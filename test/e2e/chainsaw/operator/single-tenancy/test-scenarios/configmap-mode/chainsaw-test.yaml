apiVersion: chainsaw.kyverno.io/v1alpha1
kind: Test
metadata:
  name: configmap-mode-mcp-server
spec:
  description: Tests TOOLHIVE_USE_CONFIGMAP=true environment variable functionality with secrets - verifies operator uses --from-configmap flag and handles secrets without provider errors
  timeouts:
    apply: 30s
    assert: 60s
    cleanup: 30s
    exec: 300s
  steps:
  - name: verify-operator
    description: Ensure operator is ready before testing
    try:
    - assert:
        file: ../../setup/assert-operator-ready.yaml

  - name: create-test-secret
    description: Create a test secret for the MCP server
    try:
    - apply:
        file: test-secret.yaml

  - name: enable-configmap-mode
    description: Enable ConfigMap mode by setting environment variable on operator
    try:
    - script:
        content: |
          echo "Setting TOOLHIVE_USE_CONFIGMAP=true on operator deployment..."

          # Use strategic merge patch to add the environment variable to existing env array
          kubectl patch deployment toolhive-operator -n toolhive-system --type='strategic' -p='{"spec":{"template":{"spec":{"containers":[{"name":"manager","env":[{"name":"TOOLHIVE_USE_CONFIGMAP","value":"true"}]}]}}}}'

          # Wait for rollout to complete
          kubectl rollout status deployment/toolhive-operator -n toolhive-system --timeout=60s

          # Verify the environment variable was set
          echo "Verifying TOOLHIVE_USE_CONFIGMAP environment variable is set..."
          ENV_VAR=$(kubectl get deployment toolhive-operator -n toolhive-system -o jsonpath='{.spec.template.spec.containers[?(@.name=="manager")].env[?(@.name=="TOOLHIVE_USE_CONFIGMAP")].value}')
          if [ "$ENV_VAR" = "true" ]; then
            echo "✓ TOOLHIVE_USE_CONFIGMAP=true verified on operator deployment"
          else
            echo "✗ Failed to set TOOLHIVE_USE_CONFIGMAP environment variable"
            echo "Current environment variables:"
            kubectl get deployment toolhive-operator -n toolhive-system -o jsonpath='{.spec.template.spec.containers[?(@.name=="manager")].env[*]}' | jq '.'
            exit 1
          fi
      
  - name: deploy-mcpserver-configmap-mode
    description: Deploy MCPServer instance (will use ConfigMap mode due to env var)
    try:
    - apply:
        file: mcpserver.yaml
    - assert:
        file: mcpserver.yaml
    - assert:
        file: assert-mcpserver-running.yaml
    - assert:
        file: assert-mcpserver-pod-running.yaml
    - assert:
        file: assert-deployment-uses-configmap-flag.yaml

  - name: verify-configmap-functionality
    description: Verify ConfigMap is created with proper content and deployment works
    try:
    - script:
        content: |
          echo "Verifying ConfigMap mode functionality..."
          
          # Wait for ConfigMap to be created
          for i in $(seq 1 10); do
            if kubectl get configmap yardstick-runconfig -n toolhive-system >/dev/null 2>&1; then
              echo "✓ ConfigMap yardstick-runconfig exists"
              break
            fi
            echo "  Waiting for ConfigMap... (attempt $i/10)"
            sleep 2
          done
          
          # Verify ConfigMap contains runconfig.json content
          CONFIGMAP_JSON=$(kubectl get configmap yardstick-runconfig -n toolhive-system -o jsonpath='{.data.runconfig\.json}' 2>/dev/null || echo "")
          
          if [ -z "$CONFIGMAP_JSON" ]; then
            echo "✗ ConfigMap does not contain runconfig.json data"
            kubectl get configmap yardstick-runconfig -n toolhive-system -o yaml
            exit 1
          fi
          
          echo "✓ ConfigMap contains runconfig.json data"
          
          # Validate JSON structure
          if echo "$CONFIGMAP_JSON" | jq -e '.schema_version and .image and .name and .transport' > /dev/null 2>&1; then
            echo "✓ runconfig.json contains required fields"
          else
            echo "✗ runconfig.json missing required fields"
            exit 1
          fi

          # Validate secrets are included in the runconfig
          if echo "$CONFIGMAP_JSON" | jq -e '.secrets and (.secrets | length > 0)' > /dev/null 2>&1; then
            echo "✓ runconfig.json contains secrets configuration"
          else
            echo "✗ runconfig.json missing secrets configuration"
            echo "ConfigMap content:"
            echo "$CONFIGMAP_JSON" | jq '.'
            exit 1
          fi
          
          # Verify deployment arguments
          echo "Verifying deployment uses --from-configmap flag..."
          DEPLOYMENT_ARGS=$(kubectl get deployment yardstick -n toolhive-system -o jsonpath='{.spec.template.spec.containers[0].args}')
          echo "Deployment args: $DEPLOYMENT_ARGS"
          
          if echo "$DEPLOYMENT_ARGS" | grep -q -- "--from-configmap=toolhive-system/yardstick-runconfig"; then
            echo "✓ Deployment uses --from-configmap flag"
          else
            echo "✗ Deployment does not use --from-configmap flag"
            exit 1
          fi
          
          # Verify individual config flags are NOT present
          if echo "$DEPLOYMENT_ARGS" | grep -q -- "--transport=stdio"; then
            echo "✗ Deployment should not use --transport flag when using ConfigMap"
            exit 1
          fi
          
          if echo "$DEPLOYMENT_ARGS" | grep -q -- "--name=yardstick"; then
            echo "✗ Deployment should not use --name flag when using ConfigMap"
            exit 1
          fi
          
          echo "✓ Individual config flags correctly omitted"
          
          # Wait for pod to be ready
          echo "Waiting for pod to be ready..."
          kubectl wait --for=condition=Ready pod -l app=mcpserver,app.kubernetes.io/instance=yardstick -n toolhive-system --timeout=120s

          # Verify no secrets provider errors in logs
          echo "Checking pod logs for secrets provider errors..."
          POD_NAME=$(kubectl get pod -l app=mcpserver,app.kubernetes.io/instance=yardstick -n toolhive-system -o jsonpath='{.items[0].metadata.name}')
          POD_LOGS=$(kubectl logs $POD_NAME -n toolhive-system --tail=100)

          if echo "$POD_LOGS" | grep -q "secrets provider not configured"; then
            echo "✗ Pod logs contain secrets provider error:"
            echo "$POD_LOGS"
            exit 1
          fi

          if echo "$POD_LOGS" | grep -q "failed to create secrets provider"; then
            echo "✗ Pod logs contain secrets provider creation error:"
            echo "$POD_LOGS"
            exit 1
          fi

          echo "✓ No secrets provider errors found in pod logs"

          echo "✅ ConfigMap mode functionality with secrets verified successfully!"

  - name: cleanup-configmap-mode
    description: Disable ConfigMap mode to avoid affecting subsequent tests
    try:
    - script:
        content: |
          echo "Disabling ConfigMap mode by removing environment variable..."
          
          # Use JSON patch to remove the specific environment variable
          kubectl patch deployment toolhive-operator -n toolhive-system --type='json' -p='[{"op": "remove", "path": "/spec/template/spec/containers/0/env", "value": {"name": "TOOLHIVE_USE_CONFIGMAP"}}]' || echo "Environment variable may not exist to remove"
          
          # Alternative: set it to false instead of removing
          kubectl patch deployment toolhive-operator -n toolhive-system --type='strategic' -p='{"spec":{"template":{"spec":{"containers":[{"name":"manager","env":[{"name":"TOOLHIVE_USE_CONFIGMAP","value":"false"}]}]}}}}'
          
          # Wait for rollout to complete
          kubectl rollout status deployment/toolhive-operator -n toolhive-system --timeout=60s
          
          echo "✓ ConfigMap mode cleanup completed"